{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94a83c1-7300-4557-93bc-8db918555779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirq\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#define utility functions\n",
    "\n",
    "def simulate(circuit: cirq.Circuit) -> dict:\n",
    "    \"\"\"This funcion simulate a cirq circuit (without measurement) and output results in the format of histogram.\n",
    "    \"\"\"\n",
    "    simulator = cirq.Simulator()\n",
    "    result = simulator.simulate(circuit)\n",
    "    \n",
    "    state_vector=result.final_state_vector\n",
    "    \n",
    "    histogram = dict()\n",
    "    for i in range(len(state_vector)):\n",
    "        population = abs(state_vector[i]) ** 2\n",
    "        if population > 1e-9:\n",
    "            histogram[i] = population\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "\n",
    "def histogram_to_category(histogram):\n",
    "    \"\"\"This function take a histogram representations of circuit execution results, and process into labels as described in \n",
    "    the problem description.\"\"\"\n",
    "    assert abs(sum(histogram.values())-1)<1e-8\n",
    "    positive=0\n",
    "    for key in histogram.keys():\n",
    "        digits = bin(int(key))[2:].zfill(20)\n",
    "        if digits[-1]=='0':\n",
    "            positive+=histogram[key]\n",
    "        \n",
    "    return positive\n",
    "\n",
    "def count_gates(circuit: cirq.Circuit):\n",
    "    \"\"\"Returns the number of 1-qubit gates, number of 2-qubit gates, number of 3-qubit gates....\"\"\"\n",
    "    counter=Counter([len(op.qubits) for op in circuit.all_operations()])\n",
    "    \n",
    "    #feel free to comment out the following two lines. But make sure you don't have k-qubit gates in your circuit\n",
    "    #for k>2\n",
    "    for i in range(2,20):\n",
    "        assert counter[i]==0\n",
    "        \n",
    "    return counter\n",
    "\n",
    "def image_mse(image1,image2):\n",
    "    # Using sklearns mean squared error:\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
    "    return mean_squared_error(image1, image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982f8c22-c3f8-4842-9757-234b273c6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the mock data (for testing only)\n",
    "files=os.listdir(\"mock_data\")\n",
    "dataset=list()\n",
    "for file in files:\n",
    "    with open('mock_data/'+file, \"r\") as infile:\n",
    "        loaded = json.load(infile)\n",
    "        dataset.append(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204b5b91-d0b0-4d0c-abb9-511c2b6ed656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faf15637850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load the actual hackthon data (fashion-mnist)\n",
    "images=np.load('data/images.npy')\n",
    "labels=np.load('data/labels.npy')\n",
    "#you can visualize it\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images[1], cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c6fb0d-a1cd-468e-bb74-31a3e2b17d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_image=len(images)\n",
    "#new_image=[]\n",
    "#for i in range(num_image):\n",
    "#    new_image.append(images[i].resize(16,16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b949fb7-6fe1-4940-bebe-da5801d1a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from qiskit.execute_function import execute\n",
    "\n",
    "num_image=len(images)\n",
    "noramliz_const=np.max(num_image)\n",
    "for i in range(num_image):\n",
    "    images[i]=images[i]/noramliz_const\n",
    "    \n",
    "input_data=images\n",
    "Output_data=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d40248b7-27f3-4ec3-b871-9fcc77aedb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdata=[]\n",
    "for i in range(num_image):\n",
    "    if labels[i] == True:\n",
    "        outputdata.append(1)\n",
    "    else:\n",
    "        outputdata.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fc7c379-d044-407d-805e-7c4eef91f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_2_state(image):\n",
    "    \"\"\"\n",
    "    Input: image (array)\n",
    "    \n",
    "    return: the coefficients of the inintial state\n",
    "    \"\"\"\n",
    "    L,W=np.shape(image)\n",
    "    num_q=int(np.ceil(np.log(L*W)/np.log(2)))\n",
    "    cf=np.zeros((2**num_q),dtype=float)\n",
    "    flattern_im=image.flatten()\n",
    "    for i in range(L*W):\n",
    "        cf[i]=flattern_im[i]\n",
    "    norm_const=scipy.linalg.norm(cf)\n",
    "    if norm_const==0:\n",
    "        cf[0]=1\n",
    "        return cf\n",
    "    cf=cf/norm_const\n",
    "    return cf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d807604b-463a-4c5d-a665-a16df9557125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "from qiskit import  transpile\n",
    "from qiskit import BasicAer\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "#from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "from pennylane import numpy as np\n",
    "from pennylane import math\n",
    "\n",
    "\n",
    "backend = BasicAer.get_backend('statevector_simulator')\n",
    "def encode_qiskit(image):\n",
    "    \"\"\"\n",
    "    The encoder's circuit using QPIE\n",
    "    image: input image (array)\n",
    "    return qiskit circuit, number of qubuts\n",
    "    \"\"\"\n",
    "    if isinstance(image, list):\n",
    "        image=np.array(image)\n",
    "    L,W=np.shape(image)\n",
    "    num_q=int(np.ceil(np.log(L*W)/np.log(2)))\n",
    "    state_vector=Image_2_state(image)\n",
    "    q = qiskit.QuantumRegister(num_q)\n",
    "    circuit = qiskit.QuantumCircuit(q)\n",
    "    #if image[0][0]==0:\n",
    "    q_indx=[i for i in range(num_q)]\n",
    "    #print(q_indx)\n",
    "    #print(state_vector)\n",
    "    state_vector=state_vector.numpy()\n",
    "    circuit.initialize(state_vector,q_indx)#rx(np.pi,0)\n",
    "    circuit=transpile(circuit, backend=backend, optimization_level=3)\n",
    "    return circuit, num_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c058f3b-5a39-4b84-8d5e-d0e9e9e44fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_ansatz(weights,num_q,num_rep):\n",
    "    \"\"\"\n",
    "    rx, rz var ansatz\n",
    "    variational classifier\n",
    "    weights: the parameter of each rotation gate (Pennylane arraybox)\n",
    "    num_q: number of qubits\n",
    "    num_rep: the number of layers\n",
    "    \n",
    "    return qiskit variational circuit\n",
    "    \"\"\"\n",
    "    num_w=len(weights)\n",
    "    qr = qiskit.QuantumRegister(num_q)\n",
    "    qc=qiskit.QuantumCircuit(qr)\n",
    "    weights=math.unwrap(weights)\n",
    "    #print(np.shape(weights))\n",
    "    for i in range(num_rep):\n",
    "        #q_i=0\n",
    "        for j in range(num_q):\n",
    "            qc.rx(weights[i*2*num_q+2*j],j)\n",
    "            qc.rz(weights[i*2*num_q+2*j+1],j)\n",
    "            #q_i+=1\n",
    "        for j in range(num_q-1):\n",
    "            qc.cx(j,j+1)\n",
    "    for j in range(num_q):\n",
    "        qc.rx(weights[num_q*2*num_rep+2*j],j)\n",
    "        qc.rz(weights[num_q*2*num_rep+2*j+1],j)\n",
    "    \n",
    "    return qc\n",
    "            \n",
    "        \n",
    "\n",
    "def circuit_output(weights, images, num_rep=2, num_shot=1024):\n",
    "    \"\"\"\n",
    "    num_rep : number of layers\n",
    "    num_shot: number of shots\n",
    "    weights: the parameter of each rotation gate (Pennylane arraybox)\n",
    "    image: input image (array)\n",
    "    \"\"\"\n",
    "    circuit, num_q=encode_qiskit(images)\n",
    "    qr = qiskit.QuantumRegister(num_q)\n",
    "    cr= qiskit.ClassicalRegister(1)\n",
    "    qc=qiskit.QuantumCircuit(qr,cr)\n",
    "\n",
    "    var_cir=var_ansatz(weights,num_q,num_rep)\n",
    "    qc.append(circuit.to_instruction(),qr[:])\n",
    "    qc.append(var_cir,qr[:])\n",
    "    \n",
    "    qc.measure(qr[num_q//2],cr)\n",
    "    \n",
    "    backend = BasicAer.get_backend('statevector_simulator')\n",
    "    job = execute(qc, backend, shots=num_shot)\n",
    "    \n",
    "    Dict_count=job.result().get_counts()\n",
    "    \n",
    "    if '0' not in Dict_count:\n",
    "        return 1\n",
    "    \n",
    "    if '1' not in Dict_count:\n",
    "        return 0\n",
    "\n",
    "    return (Dict_count['1']-Dict_count['0'])/num_shot\n",
    "\n",
    "def variational_classifier(weights, images):\n",
    "    return circuit_output(weights, images)\n",
    "\n",
    "def cost(weights, Y, predictions):\n",
    "    #predictions = [variational_classifier(weights, x) for x in X]\n",
    "    return square_loss(Y, predictions)\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "834d7f02-00ac-4f90-b341-a5ebcbed15d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating batch accuracy\n",
      "Calculating batch cost\n",
      "Iter:     1 | Cost: 0.4000000 | Accuracy: 0.8000000 \n",
      "Calculating batch accuracy\n",
      "Calculating batch cost\n",
      "Iter:     2 | Cost: 0.2000000 | Accuracy: 0.4000000 \n",
      "Calculating batch accuracy\n",
      "Calculating batch cost\n",
      "Iter:     3 | Cost: 0.2000000 | Accuracy: 0.6000000 \n",
      "Calculating batch accuracy\n",
      "Calculating batch cost\n",
      "Iter:     4 | Cost: 0.2000000 | Accuracy: 0.4000000 \n",
      "Calculating batch accuracy\n",
      "Calculating batch cost\n",
      "Iter:     5 | Cost: 0.6000000 | Accuracy: 0.8000000 \n"
     ]
    }
   ],
   "source": [
    "opt = NesterovMomentumOptimizer(0.5)\n",
    "batch_size = 5\n",
    "num_layers=2\n",
    "_,num_qubits=encode_qiskit(images[0])\n",
    "\n",
    "weights_init = 0.01 * np.random.randn((num_layers+1)*num_qubits*2, requires_grad=True)\n",
    "weights = weights_init\n",
    "for it in range(5):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(images), (batch_size,))\n",
    "    X_batch = images[batch_index]\n",
    "    Y_batch = labels[batch_index]\n",
    "    weights, _, _ = opt.step(cost, weights, X_batch, Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    print('Calculating batch accuracy')\n",
    "    predictions = [np.sign(variational_classifier(weights, x)) for x in X_batch]\n",
    "    acc = accuracy(Y_batch, predictions)\n",
    "    print('Calculating batch cost')\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, X_batch, Y_batch), acc\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c13960-cbd5-4804-82a3-7d56130cdfef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
